{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrb7PWsXgnwIWFU4ZgeVVh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferugit/speaker-recognition-exploration/blob/testing/Extract_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = 1\n",
        "end = 1247\n",
        "batch_size = 20\n",
        "for s in range(start, end + 1, batch_size):\n",
        "  batch_end = min(s + batch_size - 1, end)\n",
        "  print(f\"batch start at {s}, and finish at {batch_end}\")"
      ],
      "metadata": {
        "id": "OdOcA8A7VDLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/clips.zip -d /content/clips"
      ],
      "metadata": {
        "id": "2ZaZOMaYts3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "-BnMaCmxuPj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGhQBKVStQBD"
      },
      "outputs": [],
      "source": [
        "import torchaudio\n",
        "from transformers import Wav2Vec2FeatureExtractor, WavLMForXVector\n",
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('microsoft/wavlm-base-sv')\n",
        "model = WavLMForXVector.from_pretrained('microsoft/wavlm-base-sv')\n",
        "\n",
        "# read database excel file\n",
        "df = pd.read_csv('path_where_data_information_are_stored', header = 0, sep = '\\t')\n",
        "A = df['Speaker_ID'].value_counts()\n",
        "\n",
        "unique_speaker_ids = A.index\n",
        "string_to_number = {string: idx for idx, string in enumerate(unique_speaker_ids)}\n",
        "\n",
        "# Map the 'Speaker_ID' column using the dictionary\n",
        "prefix = 'path_to_the_data_file'\n",
        "df['Speaker_ID'] = df['Speaker_ID'].map(string_to_number)\n",
        "\n",
        "B = df['Speaker_ID'].value_counts()\n",
        "\n",
        "# Assuming you have a DataFrame called 'df' with a column 'path' containing the file paths\n",
        "audio_files = df['Filename'].tolist()\n",
        "\n",
        "# Add the prefix to each file path and keep only .wav files\n",
        "audio_files = [os.path.join(prefix, f) for f in audio_files if f.endswith(\".wav\")]\n",
        "\n",
        "n=1\n",
        "start = 1\n",
        "end = 1247\n",
        "batch_size = 20\n",
        "for s in range(start, end + 1, batch_size):\n",
        "    batch_end = min(s + batch_size - 1, end)\n",
        "    embeddings = []\n",
        "    audios = []\n",
        "    for audio in audio_files[s:batch_end+1]:\n",
        "# Load and preprocess the audio files\n",
        "        audio_file1 = audio\n",
        "\n",
        "        waveform1, _ = torchaudio.load(audio_file1)\n",
        "\n",
        "\n",
        "        waveform1 = waveform1.squeeze()  # Remove the extra dimension\n",
        "\n",
        "        inputs1 = feature_extractor(waveform1, return_tensors=\"pt\")\n",
        "\n",
        "    # Extract embeddings for the audio files\n",
        "        embeddings1 = model(**inputs1).embeddings\n",
        "        embeddings.append(embeddings1)\n",
        "        audios.append(audio)\n",
        "    data = {'name':audios,'embeddings':[embedding.detach().numpy() for embedding in embeddings]}\n",
        "    df = pd.DataFrame(data)\n",
        "    path1 = \"/content/model1embeddings\" + str(s) + \".tsv\"\n",
        "    df.to_csv(path1, sep='\\t', index=False)\n",
        "    print(\"Data has been successfully written to.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Delete the Data Information File Before\n",
        "# Get the list of all .tsv files in the directory\n",
        "file_list = glob.glob(\"*.tsv\")\n",
        "\n",
        "# Initialize an empty DataFrame to store the merged data\n",
        "merged_data = pd.DataFrame()\n",
        "\n",
        "# Iterate over each file in the list\n",
        "for file in file_list:\n",
        "    # Read the current file into a DataFrame\n",
        "    df = pd.read_csv(file, sep='\\t')\n",
        "\n",
        "    # Append the data to the merged_data DataFrame\n",
        "    merged_data = merged_data.append(df, ignore_index=True)\n",
        "\n",
        "# Write the merged data to a new .tsv file\n",
        "merged_data.to_csv(\"merged_file.tsv\", sep='\\t', index=False)\n"
      ],
      "metadata": {
        "id": "dc4zdKHKM5JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/clips3.zip -d /content/clips3\n",
        "!pip install speechbrain"
      ],
      "metadata": {
        "id": "iOEjxL-2e_J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
        "\n",
        "# read database excel file\n",
        "df = pd.read_csv('path_where_data_information_are_stored', header = 0, sep = '\\t')\n",
        "A = df['Speaker_ID'].value_counts()\n",
        "\n",
        "unique_speaker_ids = A.index\n",
        "string_to_number = {string: idx for idx, string in enumerate(unique_speaker_ids)}\n",
        "\n",
        "\n",
        "# Map the 'Speaker_ID' column using the dictionary\n",
        "prefix = 'path_to_the_data_file'\n",
        "df['Speaker_ID'] = df['Speaker_ID'].map(string_to_number)\n",
        "\n",
        "B = df['Speaker_ID'].value_counts()\n",
        "\n",
        "# Assuming you have a DataFrame called 'df' with a column 'path' containing the file paths\n",
        "audio_files = df['Filename'].tolist()\n",
        "\n",
        "# Add the prefix to each file path and keep only .wav files\n",
        "audio_files = [os.path.join(prefix, f) for f in audio_files if f.endswith(\".wav\")]\n",
        "\n",
        "n=1\n",
        "start = 1\n",
        "end = 1247\n",
        "batch_size = 20\n",
        "\n",
        "for s in range(start, end + 1, batch_size):\n",
        "    batch_end = min(s + batch_size - 1, end)\n",
        "    embeddings = []\n",
        "    audios = []\n",
        "    for audio in audio_files[s:batch_end+1]:\n",
        "\n",
        "# Load and preprocess the audio files\n",
        "        signal  =classifier.load_audio(audio)\n",
        "        embeddings1 = classifier.encode_batch(signal, normalize=True)\n",
        "\n",
        "\n",
        "        embeddings.append(embeddings1)\n",
        "        audios.append(audio)\n",
        "    data = {'name':audios,'embeddings':embeddings}\n",
        "    df = pd.DataFrame(data)\n",
        "    path1 = \"/content/model2embeddings\" + str(s) + \".tsv\"\n",
        "    df.to_csv(path1, sep='\\t', index=False)\n",
        "    print(\"Data has been successfully written to.\")"
      ],
      "metadata": {
        "id": "JpGdkcaPfGss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory path where the WAV files are located\n",
        "directory = \"/content\"\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "file_list = os.listdir(directory)\n",
        "\n",
        "# Iterate through the file list and delete the WAV files\n",
        "for file_name in file_list:\n",
        "    if file_name.endswith(\".wav\"):\n",
        "        file_path = os.path.join(directory, file_name)\n",
        "        os.remove(file_path)"
      ],
      "metadata": {
        "id": "8C_9uTH-nMDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Delete the Data Information File Before\n",
        "# Get the list of all .tsv files in the directory\n",
        "file_list = glob.glob(\"*.tsv\")\n",
        "\n",
        "# Initialize an empty DataFrame to store the merged data\n",
        "merged_data = pd.DataFrame()\n",
        "\n",
        "# Iterate over each file in the list\n",
        "for file in file_list:\n",
        "    # Read the current file into a DataFrame\n",
        "    df = pd.read_csv(file, sep='\\t')\n",
        "\n",
        "    # Append the data to the merged_data DataFrame\n",
        "    merged_data = merged_data.append(df, ignore_index=True)\n",
        "\n",
        "# Write the merged data to a new .tsv file\n",
        "merged_data.to_csv(\"merged__file.tsv\", sep='\\t', index=False)\n"
      ],
      "metadata": {
        "id": "ALA9pBdShlEr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}